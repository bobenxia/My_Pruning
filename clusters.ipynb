{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入对于的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1个图片输入通道, 6个输出通道, 5x5 面积的卷积核\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 10)  # 5*5来源于图片维度中\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 最大池化层通过了一个2*2的窗口\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), (2, 2))\n",
    "        # 如果大小是正方形，则可以用单个数字指定\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = torch.flatten(x, 1) # 除batch（批量）使用的维度外的所有尺寸都要打平，即把高维降成一维\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().cuda()\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4945, -1.1050, -0.1268,  0.3931, -0.5763, -0.3752,  0.2148,  1.0043,\n",
      "         -0.1475, -0.2972]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/changliang/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "# 前向\n",
    "input = torch.randn(1, 1, 32, 32, requires_grad=True).cuda()\n",
    "out = net(input)\n",
    "print(out)\n",
    "\n",
    "# 反向\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、对模型进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight (6, 1, 5, 5)\n",
      "1 conv2.weight (16, 6, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "from utils.model_utils import *\n",
    "model_utils = ModelUtils(local_rank=0)\n",
    "model_utils.register_state(model=net)\n",
    "\n",
    "kernel_namedvalue_list = model_utils.get_all_conv_kernel_namedvalue_as_list()\n",
    "for i in range(len(kernel_namedvalue_list)):\n",
    "        print(i, kernel_namedvalue_list[i].name, kernel_namedvalue_list[i].value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[0, 2], [1, 3, 5], [4]], 1: [[3, 14, 15], [0, 4, 12, 13], [2], [9, 10], [6], [1, 7], [5, 8], [11]]}\n"
     ]
    }
   ],
   "source": [
    "# 获取聚类的层\n",
    "target_deps = [3, 8]\n",
    "pacesetter_dict = None\n",
    "layer_idx_to_clusters = get_layer_idx_to_clusters(kernel_namedvalue_list=kernel_namedvalue_list,\n",
    "                                                        target_deps=target_deps,\n",
    "                                                        pacesetter_dict=pacesetter_dict)\n",
    "print(layer_idx_to_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、生成 merge matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3333, 0.0000, 0.3333, 0.0000, 0.3333],\n",
      "        [0.5000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3333, 0.0000, 0.3333, 0.0000, 0.3333],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.3333, 0.0000, 0.3333, 0.0000, 0.3333]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "deps = [6, 16]\n",
    "param_name_to_merge_matrix = generate_merge_matrix_for_kernel(deps=deps,\n",
    "                                                                      layer_idx_to_clusters=layer_idx_to_clusters,\n",
    "                                                                      kernel_namedvalue_list=kernel_namedvalue_list)\n",
    "print(param_name_to_merge_matrix['conv1.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1.weight', 'conv2.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.bias', 'bn2.weight', 'bn2.bias'])\n"
     ]
    }
   ],
   "source": [
    "add_vecs_to_merge_mat_dicts(param_name_to_merge_matrix)\n",
    "print(param_name_to_merge_matrix.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （举例）获取梯度，并和 merge matrix 相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "for name, params in net.named_parameters():\n",
    "    print(name, params.shape)\n",
    "    # 获取了第一层卷积的梯度\n",
    "    conv1_grad = params.grad\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 25])\n"
     ]
    }
   ],
   "source": [
    "p_size = conv1_grad.size()\n",
    "# 将梯度 reshape 成 (batch_size, -1) 的形状\n",
    "g_mat = conv1_grad.reshape(p_size[0], -1)\n",
    "print(g_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0396,  0.8630, -0.4818, -1.2639,  0.5858, -0.2540,  0.7740, -1.3581,\n",
       "          1.4525, -0.7023, -1.0456, -1.3194, -0.2839, -0.9921, -0.0654, -1.5389,\n",
       "         -0.2749,  1.3421, -0.9044,  1.1340, -0.0627, -1.2317, -2.0808, -0.2170,\n",
       "         -0.2554],\n",
       "        [ 1.7174, -0.8448,  0.9213, -0.1279, -0.7719,  2.0492,  0.0197, -0.2615,\n",
       "         -0.6791, -2.4863,  0.3439, -1.4839,  0.2268,  1.2236,  0.3676, -0.4354,\n",
       "          0.4534,  2.8289, -0.3710,  1.1506, -0.1032, -2.1530,  0.9907,  0.6596,\n",
       "          0.5187],\n",
       "        [-2.0396,  0.8630, -0.4818, -1.2639,  0.5858, -0.2540,  0.7740, -1.3581,\n",
       "          1.4525, -0.7023, -1.0456, -1.3194, -0.2839, -0.9921, -0.0654, -1.5389,\n",
       "         -0.2749,  1.3421, -0.9044,  1.1340, -0.0627, -1.2317, -2.0808, -0.2170,\n",
       "         -0.2554],\n",
       "        [ 1.7174, -0.8448,  0.9213, -0.1279, -0.7719,  2.0492,  0.0197, -0.2615,\n",
       "         -0.6791, -2.4863,  0.3439, -1.4839,  0.2268,  1.2236,  0.3676, -0.4354,\n",
       "          0.4534,  2.8289, -0.3710,  1.1506, -0.1032, -2.1530,  0.9907,  0.6596,\n",
       "          0.5187],\n",
       "        [ 1.6787,  1.2665, -0.4953,  1.8523,  0.1142, -0.0523,  0.5207,  3.8604,\n",
       "          0.8378, -0.9447,  2.4467, -1.6236, -1.5093, -0.7909,  0.2834, -3.1665,\n",
       "          1.1321,  2.3272,  1.3492, -3.5730,  0.4124,  0.6680,  2.1597, -2.1095,\n",
       "         -2.1427],\n",
       "        [ 1.7174, -0.8448,  0.9213, -0.1279, -0.7719,  2.0492,  0.0197, -0.2615,\n",
       "         -0.6791, -2.4863,  0.3439, -1.4839,  0.2268,  1.2236,  0.3676, -0.4354,\n",
       "          0.4534,  2.8289, -0.3710,  1.1506, -0.1032, -2.1530,  0.9907,  0.6596,\n",
       "          0.5187]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将上面得到的 merge_matrix 的第一项 乘以 reshape 后的梯度\n",
    "# 实现 类内的梯度都变成一致 的功能\n",
    "param_name_to_merge_matrix['conv1.weight'].matmul(g_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6329, -3.1539,  0.5518, -1.4467,  0.6566,  0.1471,  0.6453, -0.7972,\n",
      "          2.2775,  0.0403, -2.8020, -0.5291,  0.5153,  0.1309,  1.2363, -2.9589,\n",
      "         -0.9837, -0.5219,  0.6431,  1.9916,  1.1198, -1.8530, -1.0454, -0.3382,\n",
      "          0.6545],\n",
      "        [ 2.5459, -0.2484,  0.0402,  1.8763, -3.3801,  3.6180,  0.1552, -1.0768,\n",
      "          1.2706, -1.5935,  0.6328, -0.8717,  1.2098,  1.0271,  3.0224,  1.5558,\n",
      "          0.6416,  4.4933, -0.9768,  1.6233,  0.7888, -1.8414,  1.1348,  0.9133,\n",
      "          0.1807],\n",
      "        [-2.4463,  4.8799, -1.5154, -1.0811,  0.5150, -0.6551,  0.9028, -1.9190,\n",
      "          0.6275, -1.4449,  0.7108, -2.1098, -1.0830, -2.1150, -1.3670, -0.1189,\n",
      "          0.4339,  3.2061, -2.4520,  0.2764, -1.2452, -0.6104, -3.1162, -0.0959,\n",
      "         -1.1653],\n",
      "        [ 1.6050, -2.1427,  2.6661, -3.1526, -1.6934,  1.6422, -0.6681, -1.2742,\n",
      "         -2.5014, -2.5893, -1.2991, -0.4299, -2.5529,  2.6336, -0.2178,  0.5499,\n",
      "          1.1212,  3.8123,  1.8353,  0.6225,  0.8001, -5.3941,  4.0392, -0.1495,\n",
      "          2.6676],\n",
      "        [ 1.6787,  1.2665, -0.4953,  1.8523,  0.1142, -0.0523,  0.5207,  3.8604,\n",
      "          0.8378, -0.9447,  2.4467, -1.6236, -1.5093, -0.7909,  0.2834, -3.1665,\n",
      "          1.1321,  2.3272,  1.3492, -3.5730,  0.4124,  0.6680,  2.1597, -2.1095,\n",
      "         -2.1427],\n",
      "        [ 1.0013, -0.1433,  0.0575,  0.8926,  2.7576,  0.8872,  0.5720,  1.5666,\n",
      "         -0.8065, -3.2762,  1.6979, -3.1501,  2.0236,  0.0101, -1.7020, -3.4119,\n",
      "         -0.4026,  0.1812, -1.9713,  1.2060, -1.8986,  0.7766, -2.2018,  1.2149,\n",
      "         -1.2921]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(g_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、生成 decay matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.1\n",
    "weight_decay_bias = 0\n",
    "centri_strength = 0.06\n",
    "param_name_to_decay_matrix = generate_decay_matrix_for_kernel_and_vecs(\n",
    "                    deps=deps,\n",
    "                    layer_idx_to_clusters=layer_idx_to_clusters,\n",
    "                    kernel_namedvalue_list=kernel_namedvalue_list,\n",
    "                    weight_decay=weight_decay,\n",
    "                    weight_decay_bias=weight_decay_bias,\n",
    "                    centri_strength=centri_strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （举例）\n",
    "前面对于第一层卷积的聚类结果为 0: [[0, 2], [1, 3, 5], [4]]\n",
    "之前的推导中，需要将权重衰减项，替换成\n",
    "\n",
    "-n·a ----> -[(n+y) - y/count]·a -y/count·(b+c+...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n",
      "tensor([[ 0.1300,  0.0000, -0.0300,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.1400,  0.0000, -0.0200,  0.0000, -0.0200],\n",
      "        [-0.0300,  0.0000,  0.1300,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0200,  0.0000,  0.1400,  0.0000, -0.0200],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.1000,  0.0000],\n",
      "        [ 0.0000, -0.0200,  0.0000, -0.0200,  0.0000,  0.1400]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(param_name_to_decay_matrix['conv1.weight'].shape)\n",
    "print(param_name_to_decay_matrix['conv1.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6, 25])\n"
     ]
    }
   ],
   "source": [
    "for name, params in net.named_parameters():\n",
    "    print(name, params.shape)\n",
    "    # 获取了第一层卷积的参数\n",
    "    conv1_params = params\n",
    "    break\n",
    "\n",
    "p_size = conv1_params.size()\n",
    "# 将梯度 reshape 成 (batch_size, -1) 的形状\n",
    "param_mat = conv1_params.reshape(p_size[0], -1)\n",
    "print(param_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1169e-02,  1.7027e-02, -1.1201e-02,  8.1528e-03, -2.3723e-02,\n",
       "         -2.1395e-02, -2.4254e-02,  1.7864e-02,  1.3272e-03, -2.5312e-02,\n",
       "         -2.1429e-02,  1.5881e-02, -6.5480e-03, -4.0760e-03,  1.2942e-02,\n",
       "          1.1402e-03, -1.3104e-02, -2.0617e-02,  3.5007e-03,  1.6871e-02,\n",
       "          1.8786e-02, -1.4906e-04,  1.6725e-02,  1.0890e-02, -2.0234e-02],\n",
       "        [-3.0975e-03, -3.1905e-02,  1.7929e-03, -1.8728e-02, -1.3165e-02,\n",
       "         -2.3963e-03, -1.7731e-02, -1.1764e-02,  3.0402e-03,  1.5733e-02,\n",
       "          1.7867e-02, -2.3607e-02,  1.2589e-02, -1.9807e-03,  2.4690e-02,\n",
       "         -2.5431e-02, -3.6354e-03, -1.2870e-02, -1.5690e-02,  2.6999e-03,\n",
       "         -4.9478e-03,  3.3441e-03, -2.9080e-02,  2.9334e-04, -2.3720e-02],\n",
       "        [-2.0614e-02,  8.6912e-04, -8.5209e-03,  1.9991e-02,  2.9166e-02,\n",
       "          6.8650e-03,  4.5499e-03, -1.4297e-02, -1.9930e-02,  2.5329e-02,\n",
       "          4.2086e-03,  1.7595e-02, -1.4575e-02,  7.2445e-03,  1.7970e-03,\n",
       "         -2.1384e-02,  1.4028e-04, -4.0869e-03, -5.1292e-03, -1.4007e-02,\n",
       "         -2.2037e-02,  9.1810e-03, -3.0342e-03, -1.3559e-02,  1.3420e-02],\n",
       "        [ 1.6246e-02,  1.0414e-02,  1.5211e-02,  1.9250e-02, -1.1666e-03,\n",
       "         -1.9101e-02,  2.0494e-02, -9.9458e-03, -1.5467e-02, -1.4228e-02,\n",
       "          2.5983e-02, -1.1840e-02, -5.2104e-03, -1.1428e-03,  2.4234e-02,\n",
       "          1.7367e-02,  2.0136e-02,  1.9263e-02,  1.8775e-02,  3.7474e-03,\n",
       "         -1.1308e-02,  1.5725e-02,  1.2379e-03, -2.0565e-02, -8.5862e-03],\n",
       "        [-3.4474e-03, -1.5349e-02,  1.9447e-02,  9.8415e-03,  4.6844e-03,\n",
       "         -1.1848e-02, -3.5803e-03,  1.5806e-02, -1.7889e-02, -8.7153e-03,\n",
       "          9.7776e-03, -2.0326e-03,  1.6854e-02,  9.8722e-03, -1.9220e-02,\n",
       "          9.1019e-03, -1.6711e-02,  1.4636e-03,  2.5788e-04, -1.7654e-02,\n",
       "          1.2481e-02,  1.7255e-03, -6.3814e-03,  4.6164e-03,  1.2754e-02],\n",
       "        [ 6.1645e-03,  2.5483e-02, -1.5124e-02,  8.8509e-03, -7.9399e-03,\n",
       "         -1.4972e-02,  1.1930e-02, -2.1776e-02, -9.8219e-03,  3.6315e-05,\n",
       "         -1.9448e-02,  8.2537e-03,  2.3617e-02,  3.9540e-03, -2.7815e-02,\n",
       "         -1.2064e-02,  5.8194e-03,  3.5845e-03,  1.9325e-02,  1.8418e-02,\n",
       "         -1.2299e-02,  1.0571e-02,  2.1874e-02, -2.0179e-02,  4.9508e-03]],\n",
       "       device='cuda:0', grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_name_to_decay_matrix['conv1.weight'].matmul(param_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1294,  0.1400, -0.1070,  0.1037, -0.1381, -0.1610, -0.1885,  0.1183,\n",
      "         -0.0266, -0.1582, -0.1662,  0.1620, -0.0805, -0.0195,  0.1085, -0.0308,\n",
      "         -0.1062, -0.1752,  0.0188,  0.1108,  0.1113,  0.0160,  0.1302,  0.0631,\n",
      "         -0.1392],\n",
      "        [ 0.0048, -0.1944,  0.0136, -0.1053, -0.1101, -0.0606, -0.0925, -0.1279,\n",
      "         -0.0088,  0.1003,  0.1422, -0.1815,  0.1174, -0.0113,  0.1807, -0.1841,\n",
      "          0.0052, -0.0680, -0.0700,  0.0480, -0.0666,  0.0580, -0.1892, -0.0487,\n",
      "         -0.1824],\n",
      "        [-0.1884,  0.0390, -0.0902,  0.1777,  0.1925,  0.0157, -0.0085, -0.0827,\n",
      "         -0.1594,  0.1583, -0.0060,  0.1727, -0.1307,  0.0512,  0.0389, -0.1716,\n",
      "         -0.0234, -0.0719, -0.0351, -0.0822, -0.1438,  0.0743,  0.0067, -0.0897,\n",
      "          0.0711],\n",
      "        [ 0.1257,  0.0701,  0.0974,  0.1320, -0.0351, -0.1650,  0.1465, -0.1165,\n",
      "         -0.1245, -0.0870,  0.1929, -0.1080,  0.0062, -0.0061,  0.1779,  0.0834,\n",
      "          0.1538,  0.1329,  0.1454,  0.0545, -0.1064,  0.1353,  0.0003, -0.1791,\n",
      "         -0.0879],\n",
      "        [-0.0345, -0.1535,  0.1945,  0.0984,  0.0468, -0.1185, -0.0358,  0.1581,\n",
      "         -0.1789, -0.0872,  0.0978, -0.0203,  0.1685,  0.0987, -0.1922,  0.0910,\n",
      "         -0.1671,  0.0146,  0.0026, -0.1765,  0.1248,  0.0173, -0.0638,  0.0462,\n",
      "          0.1275],\n",
      "        [ 0.0627,  0.1643, -0.0922,  0.0670, -0.0775, -0.1392,  0.0929, -0.1905,\n",
      "         -0.0892,  0.0022, -0.0910,  0.0176,  0.1863,  0.0258, -0.1475, -0.1006,\n",
      "          0.0643,  0.0349,  0.1488,  0.1462, -0.1126,  0.1031,  0.1293, -0.1767,\n",
      "         -0.0033]], device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(param_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、更新梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csgd_gradient = param_name_to_merge_matrix['conv1.weight'].matmul(g_mat) + param_name_to_decay_matrix['conv1.weight'].matmul(param_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(csgd_gradient.reshape(p_size).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "for name, params in net.named_parameters():\n",
    "    print(name, params.shape)\n",
    "    # 获取了第一层卷积的参数\n",
    "    params.grad.copy_(csgd_gradient.reshape(p_size))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b1c112e95b955b50715db3c222707c1a557055023d719838474e0aba5040c16"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('open-mmlab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
